# Lecture 4 - Lexical Analysis

- A token is a syntactic category or grouping of characters
- A lexeme is a sequence of characters in a token
- The rule of description is a pattern

- The main function of the lex is
  - Discard whatever does not contribute to tparsing like whitespaces and comments
  - Construct constants based on value
  - Recognize keywords and identifiers

- Tokens are generated by reading input streams as characters
- Extra tokens read are pushed back to the code to ask it again in the next sequence
  - This is required due to lookahead
  - Can be implemented by a buffer
- Lexemes are sent to the parsing phase

- Problems in Lexical analysers
  - Scans text character by character, needs efficient IO
  - Lookahead characters give context, and when token ends; The first character cannot give the above information

- The lexer puts the lexeme in the symbol table with the type of token. The interface is
  - Insert(s, t) : save lexeme s and token t and return parameter
  - Lookup(s) : check if lexeme s exists

- Symbol Table is implemented with the following fields
  - Token
  - Lexeme
  - Type
  - Address
  - ...