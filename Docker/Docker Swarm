docker swarm init - Initialises the swarm 

Swarm is a multi-host cluster and the node calling init acts as the master and a worker. The 
workers can join the cluster with the swarm token.

The standard compose file can be use to drive the docker swarm, but ignores the build service key.

docker stack deploy -c <compose-file> <app>- used to deploy stacks specified by the compose files

docker stack ls - list all the stacks deployed to the swarms
docker service ls - list all the services related to the swarm, works only with docker swarm

You can deploy multiple stacks running in parallel, for example a front-end, back-end and 
monitoring stack.

docker stack services <appname> - list ot services in a given stack
docker service scale <app-service> = <replicas> - scaling up a service 
docker swarm leave -f - leave the swarm and destroy it.
docker-machine ls - gives the virtual machines set up
docker-machine start <vmname> - starts the VM

For setting up swarm on 2 machines:
1. Log into a machine and do docker swarm init.
2. Specify a network adapter for the swarm.
3. In the other machine, join using docker swarm join
4. Push the application images to DockerHub
5. docker-machine env <vmname> gives the environment variables
6. Use 5 to set the env variables on the VM according to your local machine to execute in the VM
daemon.
7. Do docker stack deploy -c <YAML file> <app>
8. Done, docker swarm with 2 machines is set up

docker node is the management command of docker swarm nodes with promotion to managers, details,
etc.

services display tasks in the service and service monitoring. We can create services inside 
services that can be scaled as well.

docker service is the only way you can interact with the tasks, by scaling methods.

In the deploy configuration, you define:
1. replicas
2. update configs: parallelism and delay
3. restart policy

deploy: placements: constraints allows you to place constraints on services to fill other nodes
on the swarm.

To bring down nodes for maintenance or so, we update --availibility = drain and the other nodes
take the capabilities of that node and balance them amongst each other until the node comes back
up.

We have to add a update --force to the service to bring the node back up after update --availibility = active.
